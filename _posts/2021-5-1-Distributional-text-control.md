---
layout: post
title: "A Distributional Approach to Controlled Text Generation"
author: Muhammad Khalifa
comments: true
published: true
---
> 
I and my co-authors recently wrote a blogpost on our ICLR 2021 paper "A Distributional Approach to Controlled Text Generation"...
<!--more-->

I and my co-authors recently wrote a [blogpost](https://europe.naverlabs.com/blog/debiasing-large-pretrained-language-models-using-distributional-control/) on our ICLR 2021 [paper](https://openreview.net/forum?id=jWkw45-9AbL) : A Distributional Approach to Controlled Text Generation. From this post, you should learn:
* What we mean by distributionally controlled text generation, and how previous approaches have completely ignored this aspect of control.
* How this task reduces to Exponential Family Energy-Based Models, and how we can leverage the EBM through a "distillation" process into an autoregressive policy for generation.
* An overview of our results and experiments in the paper.
* Finally, possibly yet unsolved problems with our technique.


The blogpost is on naver's website [here](https://europe.naverlabs.com/blog/debiasing-large-pretrained-language-models-using-distributional-control/). Enjoy!
<h2 id="muhammad-khalifa">Muhammad Khalifa</h2>
<p>I am a computer science master&#39;s student at <em>Cairo University</em>. My master&#39;s work is on Low-resource multi-dialectal Arabic NLU and abstractive summarization. Thus, my main research interests are <strong>Natural Language Generation</strong>, <strong>Unsupervised Learning</strong>, and <strong>Low-Resource NLU</strong>. My interests are driven by the urgent need to save scarce-data languages and tasks by building fully unsupervised approaches that perform comparably to supervised ones. I am currenlty an Applied Scientist Intern at Amazon Web Services, working on multiple projects including dialogue summarization and Document Image Understanding. I previously did a research internship at Naver Labs Europe and worked on Controlled text generation and Energy-based models. Before that, I worked as a Machine learning research engineer at Sypron Solutions, where I investigated <strong>time-series analyis and anomaly detection</strong> for a predictive maintenance system, and designed a multi-node stream processing pipeline with <em>Spark Streaming</em>, <em>Kafka</em>, and <em>Cassandra DB</em>. </p>
<h2 id="updates-">Updates:</h2>
<p><strong>March 1st, 2021:</strong> My internship at AWS was extended. Now I am working on Document Image Understanding!</p>
<p><strong>Jan 12th, 2021:</strong> TWO papers accepted at <a href="https://openreview.net/forum?id=jWkw45-9AbL">ICLR</a> 2021 and <a href="https://arxiv.org/abs/2101.04758">EACL</a> 2021. </p>
<p><strong>October 12th, 2020:</strong> Started an applied scientist internship at Amazon Web Services, working with Miguel Ballesteros and Kathleen Mckeown on summarization.</p>
<p><strong>July 21th, 2020:</strong> My paper on book success prediction (with Professor Aminul Islam) via pre-trained embeddings and readability scores is now live on <a href="https://arxiv.org/abs/2007.11073">arxiv</a>.</p>
<p><strong>May 5th, 2020:</strong> Started an Internship in NAVER Labs Europe working on Controlled Text Generation with distributional constraints!</p>
<h2 id="publications-">Publications:</h2>
<p><strong>Muhammad Khalifa</strong>, Muhammad Abdul-Mageed, Khaled Shaalan. <em>&quot;Self-Training Pre-Trained Language Models for Zero-and Few-Shot Multi-Dialectal Arabic Sequence Labeling.&quot;</em> In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume 2021 (pp. 769â€“782). Association for Computational Linguistics.</p>
<p><strong>Muhammad Khalifa*</strong>, Hady Elsahar*, Marc Dymetman*. <em>&quot;A Distributional Approach to Controlled Text Generation&quot;.</em> In International Conference on Learning Representations 2021.</p>
<p>Mustafa Jarrar, Eman Karajah, <strong>Muhammad Khalifa</strong>, Khaled Shaalan. <em>&quot;Extracting Synonyms from Bilingual Dictionaries&quot;.</em> In Proceedings of the 11th International Global Wordnet Conference (GWC2021). Global Wordnet Association (2021).</p>
<p><strong>Muhammad Khalifa</strong>, Khaled Shaalan. <em>&quot;Character Convolutions for Arabic Named Entity Recognition with Long Short-Term Memory Networks&quot;</em>. In Speech &amp; Language, Volume 58, 2019, Pages 335-346, ISSN 0885-2308.</p>
<p><strong>Muhammad Khalifa</strong>, Noura Hussein. <em>&quot;Ensemble Learning for Irony Detection in Arabic Tweets&quot;</em>. In FIRE (Working Notes), pp. 433-438. 2019.</p>
